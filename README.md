# Ubble Coding Test

Welcome to Ubble coding test ! Your goal will be to create a mini-ubble project, enjoy !

## Overview

The project is divided into two directories.

- `./streamer` : a python script that launches your camera and detects your face.
- `./api` : a vanilla django api, with Postgresql.

## Requirements

- [Docker](https://www.docker.com/get-started)
- Python 3.6
- [Aws cli](https://docs.aws.amazon.com/cli/latest/userguide/install-macos.html). You *do not* need an AWS account for this project !

## Getting started

- First start the api : `docker-compose up -d api`. You may need to run the first migrations : `docker-compose exec api django-admin migrate`.
- Create dynamodb table (chose a name) : `aws dynamodb create-table --table-name ubbledb --attribute-definitions AttributeName=id,AttributeType=S --key-schema AttributeName=id,KeyType=HASH --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 --endpoint-url http://localhost:4569`
- Create a S3 bucket : `aws s3api create-bucket --bucket ubblebucket --endpoint-url http://localhost:4572`
- Make the bucket easily readable : `aws s3api put-bucket-acl --bucket ubblebucket --acl public-read --endpoint-url http://localhost:4572`

Once you've done all these steps, the API and different storage are up and running, just as if they were distant services. It is now time to look at the [streamer](./streamer/README.md), which is the client that will run on your machine, access the webcam and interact with the API.

## Objectives

Your goal is to save all the data generated by one session of the streamer. For each iteration of the streamer algorithm, you need to save :
- the frame on which the streamer has run
- the feedback returned for that frame
- the face extracted for that frame, if there was one

Once the streamer is done (you can terminate it based on a number of extracted faces), you must be able to fetch all the extracted faces by one API call which is looking at postgres data and returning S3 signed urls. This API call should be able to return data from previous sessions of the streamer.

## Evaluation criteria & constraints

- Plain images should only be saved in S3.
- While the streamer is running, no data should be saved in postgres, only in `dynamodb` and `S3`.
- You will be evaluated on your capacity to write well architectured, understandable and well tested code.

## How to submit your proposal

You should have received a compressed version of this repository. To submit your answer, simply commit your changes in a new branch and return us a compressed version of the updated repository.
